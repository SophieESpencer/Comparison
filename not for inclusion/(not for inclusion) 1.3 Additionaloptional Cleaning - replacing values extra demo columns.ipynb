{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country          [Turkey, Austria, Germany, Egypt, France, Iran...\n",
      "IDSTUD           [50010601, 50010602, 50010603, 50010604, 50010...\n",
      "ASBH02A                                            [1, 2, Yes, No]\n",
      "ASBH02B                                  [nan, 2.0, 1.0, 3.0, 4.0]\n",
      "ASBH03A                                    [1, 2, 9, Yes, No, nan]\n",
      "ASBH04           [1, 2, 9, 4, 3, Always, Never, Almost always, ...\n",
      "ASBH15A          [99, 5, 2, 4, 7, 1, 6, 3, 8, 10, 9, <Master’s ...\n",
      "ASBH15B          [7, 3, 99, 6, 4, 5, 8, 2, 1, 10, 9, <Master’s ...\n",
      "ASBH16           [6, 3, 5, 4, 9, 2, 1, Finish <Short-cycle tert...\n",
      "ASBH17A          [99, 1, 3, 4, 10, 12, 11, 8, 2, 7, 6, 5, 9, Co...\n",
      "ASBH17B          [9, 2, 99, 5, 3, 6, 12, 4, 10, 8, 11, 7, 1, Co...\n",
      "ASBH18AA                                [9, 1, 2, 6, Yes, No, nan]\n",
      "ASBH18AB                                [1, 9, 2, 6, Yes, No, nan]\n",
      "ASBG01                             [2, 1, nan, Girl, Boy, <Other>]\n",
      "ASBG03           [1, 3, 2, 9, 4, nan, I always speak <language ...\n",
      "ASDAGE           [10.0, 9.0, 11.0, 12.0, 14.0, 8.0, 99.0, 13.0,...\n",
      "ASBG10A          [1, 2, 3, 9, 4, nan, Agree a little, Agree a l...\n",
      "ASBG10B          [1, 2, 4, 3, 9, nan, Disagree a little, Agree ...\n",
      "ASBG10C          [1, 2, 4, 9, 3, nan, Agree a little, Agree a l...\n",
      "ASBG10D          [1, 2, 3, 4, 9, nan, Agree a little, Agree a l...\n",
      "ASBG10E          [1, 2, 4, 3, 9, nan, Disagree a little, Agree ...\n",
      "ASBG10F          [1, 2, 3, 4, 9, nan, Agree a lot, Agree a litt...\n",
      "ASBG11A          [4, 1, 3, 2, 9, nan, Never, Once or twice a mo...\n",
      "ASBG11B          [4, 3, 1, 2, 9, nan, Never, Once or twice a mo...\n",
      "ASBG11C          [4, 1, 3, 2, 9, nan, A few times a year, At le...\n",
      "ASBG11D          [4, 2, 1, 3, 9, nan, Once or twice a month, Ne...\n",
      "ASBG11E          [4, 9, 3, 1, 2, nan, Never, A few times a year...\n",
      "ASBG11F          [4, 3, 1, 2, 9, nan, Never, A few times a year...\n",
      "ASBG11G          [4, 3, 1, 9, 2, nan, Never, Once or twice a mo...\n",
      "ASBG11H          [4, 1, 3, 2, 9, nan, A few times a year, Never...\n",
      "ASBG11I          [4, 3, 1, 2, 9, nan, Never, At least once a we...\n",
      "ASBG11J          [4, 2, 3, 1, 9, nan, Never, A few times a year...\n",
      "ASRREA01         [575.43893, 624.14372, 566.97797, 559.10952, 5...\n",
      "ASRREA02         [557.2702, 612.68392, 568.76819, 606.69925, 57...\n",
      "ASRREA03         [561.95322, 544.73823, 532.78288, 618.60416, 5...\n",
      "ASRREA04         [573.6631, 503.87599, 529.96707, 537.07661, 58...\n",
      "ASRREA05         [567.45202, 556.77689, 574.76885, 578.13802, 5...\n",
      "ASRLIT01         [574.18458, 558.67343, 510.07336, 552.78456, 5...\n",
      "ASRLIT02         [538.50995, 490.57312, 546.94331, 549.12705, 5...\n",
      "ASRLIT03         [552.13065, 518.70781, 579.40362, 549.04198, 5...\n",
      "ASRLIT04         [544.30274, 579.02561, 573.21826, 574.22474, 5...\n",
      "ASRLIT05         [526.00088, 587.62561, 543.85171, 579.36628, 5...\n",
      "ASRINF01         [603.4214, 589.18148, 588.0798, 572.97888, 519...\n",
      "ASRINF02         [557.18476, 567.6433, 530.325, 574.68991, 555....\n",
      "ASRINF03         [579.4064, 583.6373, 608.01411, 587.09957, 541...\n",
      "ASRINF04         [589.70854, 605.92949, 592.02409, 616.07931, 5...\n",
      "ASRINF05         [607.70484, 612.32853, 604.63968, 627.0463, 54...\n",
      "ASRIIE01         [512.47061, 533.28483, 555.22771, 597.19872, 5...\n",
      "ASRIIE02         [531.55392, 570.44237, 511.40394, 550.02047, 5...\n",
      "ASRIIE03         [530.54494, 533.81285, 535.36974, 590.29351, 5...\n",
      "ASRIIE04         [532.47086, 527.90432, 577.63833, 604.19057, 5...\n",
      "ASRIIE05         [551.68836, 552.31885, 579.58198, 599.13247, 5...\n",
      "ASRRSI01         [511.66661, 509.93363, 595.41526, 602.64538, 5...\n",
      "ASRRSI02         [550.91604, 590.28715, 531.5494, 548.77512, 57...\n",
      "ASRRSI03         [541.14507, 528.73534, 554.99954, 569.19386, 5...\n",
      "ASRRSI04         [547.95804, 527.73292, 616.19334, 604.42141, 5...\n",
      "ASRRSI05         [576.53241, 552.69589, 579.88415, 591.9977, 60...\n",
      "MINAGEARRIVAL                            [nan, 3.0, 0.0, 6.0, 8.0]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply unique() to each column\n",
    "unique_values = df.apply(lambda col: col.unique())\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_columns = ['Country','ASBH02A']\n",
    "demographic_info_columns = ['ASBH02B', 'ASBH03A', 'ASBH04', 'ASBH15A', 'ASBH15B', 'ASBH16', 'ASBH17A', 'ASBH17B', 'ASBH18AA', 'ASBH18AB', 'ASBG01', 'ASBG03', 'ASDAGE','MINAGEARRIVAL' ]\n",
    "positive_feelings_in_school = ['ASBG10A', 'ASBG10B','ASBG10C', 'ASBG10D', 'ASBG10E', 'ASBG10F']\n",
    "negativeexperience_in_school_columns = ['ASBG11A', 'ASBG11B', 'ASBG11C', 'ASBG11D', 'ASBG11E', 'ASBG11F', 'ASBG11G', 'ASBG11H', 'ASBG11I', 'ASBG11J']\n",
    "assessment_score_columns = ['ASRREA01', 'ASRREA02', 'ASRREA03', 'ASRREA04', 'ASRREA05', 'ASRLIT01', 'ASRLIT02', 'ASRLIT03', 'ASRLIT04', 'ASRLIT05', 'ASRINF01', 'ASRINF02', 'ASRINF03', 'ASRINF04', 'ASRINF05', 'ASRIIE01', 'ASRIIE02', 'ASRIIE03', 'ASRIIE04', 'ASRIIE05', 'ASRRSI01', 'ASRRSI02', 'ASRRSI03', 'ASRRSI04', 'ASRRSI05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # Optional: Set max column width\n",
    "pd.set_option('display.expand_frame_repr', False)  # Optional: Do not wrap line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That was easy enough - now to do the asbh ones... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping_education_levels = {\n",
    "1: 'Did not go to school', \n",
    " 2: 'Some <Primary education—ISCED Level 1 or Lower secondary education—ISCED Level 2>', \n",
    " 3: '<Lower secondary education—ISCED Level 2>', \n",
    " 4: '<Upper secondary education—ISCED Level 3>', \n",
    " 5: '<Post-secondary, non-tertiary education— ISCED Level 4>', \n",
    " 6: '<Short-cycle tertiary education—ISCED Level 5>', \n",
    " 7: '<Bachelor’s or equivalent level—ISCED Level 6>', \n",
    " 8: '<Master’s or equivalent level—ISCED Level 7>', \n",
    " 9: '<Doctor or equivalent level—ISCED Level 8>',\n",
    " 10: 'Not applicable'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping dictionary\n",
    "reverse_mapping_education_levels = {v: k for k, v in ordinal_mapping_education_levels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ASBH15A'] = df['ASBH15A'].map(reverse_mapping_education_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ASBH15B'] = df['ASBH15B'].map(reverse_mapping_education_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ordinal_mapping_profession_levels = {\n",
    " 1: 'Has never worked for pay',\n",
    " 10: 'Professional Includes scientists,mathematicians; computer scientists,architects; engineers; life science and health pr',\n",
    " 11: 'Technician or Associate Professional Includes science, engineering, and computer associates and technicians; life scienc',\n",
    " 12: 'Not applicable',\n",
    " 2: 'Small Business Owner Includes owners of small businesses (fewer than 25 employees) such as retail shops, services, resta',\n",
    " 3: 'Clerical Worker Includes office clerks; secretaries; data entry operators; customer service clerks',\n",
    " 4: 'Service or Sales Worker Includes travel attendants; restaurant service workers; personal care workers; protective servic',\n",
    " 5: 'Skilled Agricultural or Fishery Worker Includes farmers; forestry workers; fishery workers',\n",
    " 6: 'Craft or Trade Worker Includes builders, carpenters, plumbers, electricians, metal workers; machine mechanics; handicraf',\n",
    " 7: 'Plant or Machine Operator Includes plant and machine operators; assembly-line operators; motor-vehicle drivers',\n",
    " 8: 'General'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping dictionary\n",
    "reverse_mapping_profession_levels = {v: k for k, v in ordinal_mapping_profession_levels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ASBH17A'] = df['ASBH17A'].map(reverse_mapping_profession_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ASBH17B'] = df['ASBH17B'].map(reverse_mapping_profession_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping_language = {\n",
    "     1: 'I always speak <language of test> at home',\n",
    "    2: 'I almost always speak <language of test> at home',\n",
    "    3: 'I sometimes speak <language of test> and sometimes speak another language at home',\n",
    "    4: 'I never speak <language of test> at home'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping dictionary\n",
    "reverse_mapping_language = {v: k for k, v in ordinal_mapping_language.items()}\n",
    "df['ASBG03'] = df['ASBG03'].map(reverse_mapping_language)\n",
    "df['ASBG03'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping_language_parents = {\n",
    "    1: 'Always',\n",
    "    2: 'Almost always',\n",
    "    3: 'Sometimes',\n",
    "    4: 'Never'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping dictionary\n",
    "reverse_mapping_language_parents = {v: k for k, v in ordinal_mapping_language_parents.items()}\n",
    "df['ASBH04'] = df['ASBH04'].map(reverse_mapping_language_parents)\n",
    "df['ASBH04'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to map patterns to integers\n",
    "def map_using_patterns(text):\n",
    "    # Dictionary of regex patterns to integers\n",
    "    pattern_to_integer = {\n",
    "        r'Lower secondary education': 1,\n",
    "        r'Upper secondary education': 2,\n",
    "        r'Post-secondary, non-tertiary education': 3,\n",
    "        r'Short-cycle tertiary education': 4,\n",
    "        r'Bachelor’s or equivalent level': 5,\n",
    "        r'Postgraduate degree': 6\n",
    "    }\n",
    "\n",
    "    # Check if the input is a string\n",
    "    if isinstance(text, str):\n",
    "        for pattern, integer in pattern_to_integer.items():\n",
    "            if pd.Series([text]).str.contains(pattern).any():\n",
    "                return integer\n",
    "    return text  # Return the original value if it's not a string or no pattern matches\n",
    "\n",
    "# Apply the function to the 'ASBH16' column\n",
    "df['ASBH16'] = df['ASBH16'].apply(map_using_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\"Yes\": 1, \"No\": 2}\n",
    "df['ASBH18AA']= df['ASBH18AA'].map(mapping_dict)\n",
    "df['ASBH18AB']= df['ASBH18AB'].map(mapping_dict)\n",
    "df['ASBH18AA'].unique()\n",
    "df['ASBH18AB'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict_gender = {\"Girl\": 1, \"Boy\": 2, \"<Other>\": 3}\n",
    "df['ASBG01']= df['ASBG01'].map(mapping_dict_gender)\n",
    "df['ASBG01'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing numbers representing NaN with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH03A\"] = df[\"ASBH03A\"].replace({9.0: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15a and 15b do not have 999s. replace the 10s with NaN as 10 is non applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH15A\"] = df[\"ASBH15A\"].replace({10.0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH15B\"] = df[\"ASBH15B\"].replace({10.0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH16\"] = df[\"ASBH16\"].replace({9.0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH17A\"] = df[\"ASBH17A\"].replace({12.0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ASBH17B\"] = df[\"ASBH17B\"].replace({12.0: np.nan})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
