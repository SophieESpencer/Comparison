{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('cleandata109.xlsx', index_col= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to choose a dataset from the filtered one ( z score etc. ) and then do these correlation thingies for the numeric data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_columns = ['Country','ASBH02A','avgscore']\n",
    "demographic_info_columns = ['ASBH02B', 'ASBH03A', 'ASBH04', 'ASBH15A', 'ASBH15B', 'ASBH16', 'ASBH17A', 'ASBH17B', 'ASBH18AA', 'ASBH18AB', 'ASBG01', 'ASBG03', 'ASDAGE','MINAGEARRIVAL' ]\n",
    "positive_feelings_in_school = ['ASBG10A', 'ASBG10B','ASBG10C', 'ASBG10D', 'ASBG10E', 'ASBG10F']\n",
    "negativeexperience_in_school_columns = ['ASBG11A', 'ASBG11B', 'ASBG11C', 'ASBG11D', 'ASBG11E', 'ASBG11F', 'ASBG11G', 'ASBG11H', 'ASBG11I', 'ASBG11J']\n",
    "assessment_score_columns = ['ASRREA01', 'ASRREA02', 'ASRREA03', 'ASRREA04', 'ASRREA05', 'ASRLIT01', 'ASRLIT02', 'ASRLIT03', 'ASRLIT04', 'ASRLIT05', 'ASRINF01', 'ASRINF02', 'ASRINF03', 'ASRINF04', 'ASRINF05', 'ASRIIE01', 'ASRIIE02', 'ASRIIE03', 'ASRIIE04', 'ASRIIE05', 'ASRRSI01', 'ASRRSI02', 'ASRRSI03', 'ASRRSI04', 'ASRRSI05']\n",
    "averages = ['reading_avg', 'literary_purpose_avg', 'informational_purpose_avg','interpreting_process_avg', 'straightforward_process_avg','avgscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avgscore'] = df[positive_feelings_in_school].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The below is for comparing columns that are non-numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avgscore_binned'] = pd.cut(df['avgscore'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df['ASBH02A'], df['avgscore_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>avgscore_binned</th>\n",
       "      <th>(0.997, 1.3]</th>\n",
       "      <th>(1.3, 1.6]</th>\n",
       "      <th>(1.6, 1.9]</th>\n",
       "      <th>(1.9, 2.2]</th>\n",
       "      <th>(2.2, 2.5]</th>\n",
       "      <th>(2.5, 2.8]</th>\n",
       "      <th>(2.8, 3.1]</th>\n",
       "      <th>(3.1, 3.4]</th>\n",
       "      <th>(3.4, 3.7]</th>\n",
       "      <th>(3.7, 4.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASBH02A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1317</td>\n",
       "      <td>496</td>\n",
       "      <td>256</td>\n",
       "      <td>190</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>13843</td>\n",
       "      <td>5485</td>\n",
       "      <td>3025</td>\n",
       "      <td>2071</td>\n",
       "      <td>1115</td>\n",
       "      <td>298</td>\n",
       "      <td>361</td>\n",
       "      <td>126</td>\n",
       "      <td>110</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "avgscore_binned  (0.997, 1.3]  (1.3, 1.6]  (1.6, 1.9]  (1.9, 2.2]  (2.2, 2.5]  \\\n",
       "ASBH02A                                                                         \n",
       "No                       1317         496         256         190          88   \n",
       "Yes                     13843        5485        3025        2071        1115   \n",
       "\n",
       "avgscore_binned  (2.5, 2.8]  (2.8, 3.1]  (3.1, 3.4]  (3.4, 3.7]  (3.7, 4.0]  \n",
       "ASBH02A                                                                      \n",
       "No                       32          36          13          14          16  \n",
       "Yes                     298         361         126         110         163  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cramér's V: 0.015985714584942134\n"
     ]
    }
   ],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_matrix = pd.crosstab(df['ASBH02A'], df['avgscore_binned'])\n",
    "\n",
    "# Calculate Cramér's V\n",
    "cramers_v_value = cramers_v(confusion_matrix)\n",
    "print(f\"Cramér's V: {cramers_v_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cramér's V is a statistical measure used to assess the strength of association between two nominal (categorical) variables. It is derived from the Chi-square statistic and ranges from 0 to 1, where:\n",
    "\n",
    "0 indicates no association between the variables.\n",
    "1 indicates a perfect association between the variables.\n",
    "The value you provided, 0.077, is relatively close to 0, indicating a very weak association between the two variables.\n",
    "\n",
    "Here's a general interpretation of Cramér's V:\n",
    "\n",
    "0 to 0.1: Little or no association\\\n",
    "0.1 to 0.3: Weak association\\\n",
    "0.3 to 0.5: Moderate association\\\n",
    "Above 0.5: Strong association\\\n",
    "\n",
    "Since your Cramér's V is around 0.077, it suggests that the relationship between the two categorical variables in your analysis is negligible or very weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-Square Test of Independence\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Test Statistic: 7.424803921839236\n",
      "P-value: 0.5929809854019423\n"
     ]
    }
   ],
   "source": [
    "print(f\"Chi-Square Test Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chi-Square Test Statistic: 245.83458534739597\n",
    "The Chi-Square test statistic quantifies how much the observed frequencies in your data deviate from the expected frequencies under the assumption that the two categorical variables are independent.\n",
    "A higher Chi-Square value generally indicates a greater difference between the observed and expected frequencies, suggesting a stronger association between the variables.\n",
    "In your case, the Chi-Square statistic is quite large, indicating a noticeable deviation from the expected distribution if the variables were independent.\n",
    "2. P-value: 7.553360938216542e-48\n",
    "The P-value represents the probability of observing a Chi-Square statistic as extreme as, or more extreme than, the one calculated, under the null hypothesis (which states that the two variables are independent).\n",
    "A very small P-value (like the one here, which is effectively 0.000...0000755) indicates that the observed association is highly unlikely to have occurred by chance.\n",
    "Common thresholds for significance are 0.05, 0.01, and 0.001. Your P-value is far smaller than any of these, meaning you can reject the null hypothesis with extremely high confidence, suggesting a statistically significant association between the two variables.\n",
    "Summary\n",
    "Chi-Square Test Statistic (245.83): Indicates a substantial deviation from what would be expected under independence.\n",
    "P-value (~0): Shows that this deviation is extremely unlikely to be due to random chance, indicating a statistically significant association.\n",
    "However, the earlier Cramér's V value of 0.077 suggests that while the association is statistically significant, it is not strong. This can happen when the sample size is large, leading to statistically significant results even for weak associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
